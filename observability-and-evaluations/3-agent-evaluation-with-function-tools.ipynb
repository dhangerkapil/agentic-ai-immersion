{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0786b726",
   "metadata": {},
   "source": [
    "# üìä Agent Evaluation with Function Tools - Account Balance Lookup\n",
    "\n",
    "This notebook demonstrates how to **evaluate AI agents that use function tools** using Microsoft Foundry. We'll create a **Banking Assistant Agent** with an account balance lookup tool and evaluate its responses.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "1. **Create function tools** for agent capabilities\n",
    "2. **Build an agent** with tool integration\n",
    "3. **Handle function calls** and provide results\n",
    "4. **Evaluate agent responses** including tool usage\n",
    "\n",
    "## üíº Industry Use Case: Banking Assistant with Account Lookup\n",
    "\n",
    "In banking, agents often need to:\n",
    "- **Look up account balances** via secure APIs\n",
    "- **Provide transaction history** summaries\n",
    "- **Answer questions** about account status\n",
    "\n",
    "Evaluating these tool-enabled agents ensures:\n",
    "- Tools are called correctly with proper parameters\n",
    "- Responses accurately reflect tool outputs\n",
    "- Security and compliance requirements are met\n",
    "\n",
    "### ‚ö†Ô∏è Disclaimer\n",
    "> **This is a demonstration with simulated data.** In production, account lookups would connect to secure banking APIs with proper authentication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a950a45",
   "metadata": {},
   "source": [
    "## üîê Authentication Setup\n",
    "\n",
    "Before running this notebook, authenticate with Azure CLI:\n",
    "\n",
    "```bash\n",
    "az login --use-device-code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b29247",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "notebook_path = Path().absolute()\n",
    "env_path = notebook_path.parent / '.env'\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Verify required environment variables\n",
    "project_endpoint = os.environ.get(\"AI_FOUNDRY_PROJECT_ENDPOINT\")\n",
    "tenant_id = os.environ.get(\"TENANT_ID\")\n",
    "model_deployment = os.environ.get(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "\n",
    "if not project_endpoint:\n",
    "    raise ValueError(\"üö® AI_FOUNDRY_PROJECT_ENDPOINT not set in .env\")\n",
    "\n",
    "print(f\"üîë Tenant ID: {tenant_id}\")\n",
    "print(f\"üìç Project Endpoint: {project_endpoint[:50]}...\")\n",
    "print(f\"ü§ñ Model Deployment: {model_deployment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b9c3b8",
   "metadata": {},
   "source": [
    "## 2. Initialize AI Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85974b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import AzureCliCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import PromptAgentDefinition, Tool, FunctionTool\n",
    "from openai.types.responses.response_input_param import FunctionCallOutput, ResponseInputParam\n",
    "from openai.types.evals.run_create_response import RunCreateResponse\n",
    "from openai.types.evals.run_retrieve_response import RunRetrieveResponse\n",
    "\n",
    "# Initialize credentials and clients\n",
    "credential = AzureCliCredential(tenant_id=tenant_id)\n",
    "project_client = AIProjectClient(endpoint=project_endpoint, credential=credential)\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "print(\"‚úÖ AIProjectClient initialized\")\n",
    "print(\"‚úÖ OpenAI client retrieved for evaluations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5e5df9",
   "metadata": {},
   "source": [
    "## 3. Define Function Tools\n",
    "\n",
    "We'll create two banking function tools:\n",
    "1. **get_account_balance** - Look up account balance by account number\n",
    "2. **get_recent_transactions** - Get recent transaction summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047960bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the account balance lookup tool\n",
    "get_balance_tool = FunctionTool(\n",
    "    name=\"get_account_balance\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"account_number\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The account number to look up (e.g., 'CHK-12345' or 'SAV-67890')\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"account_number\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    description=\"Get the current balance for a bank account. Returns balance and account type.\",\n",
    "    strict=True,\n",
    ")\n",
    "\n",
    "# Define the recent transactions tool\n",
    "# Note: With strict=True, ALL properties must be in the required array\n",
    "get_transactions_tool = FunctionTool(\n",
    "    name=\"get_recent_transactions\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"account_number\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The account number to look up transactions for\",\n",
    "            },\n",
    "            \"num_transactions\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Number of recent transactions to retrieve (max 10)\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"account_number\", \"num_transactions\"],  # All properties required when strict=True\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    description=\"Get recent transactions for a bank account. Returns transaction list with dates and amounts.\",\n",
    "    strict=True,\n",
    ")\n",
    "\n",
    "# Combine tools\n",
    "tools: list[Tool] = [get_balance_tool, get_transactions_tool]\n",
    "\n",
    "print(\"‚úÖ Function tools defined:\")\n",
    "for tool in tools:\n",
    "    print(f\"   ‚Ä¢ {tool.name}: {tool.description[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffcdc6",
   "metadata": {},
   "source": [
    "## 4. Implement Tool Functions\n",
    "\n",
    "These simulate backend banking API calls. In production, these would connect to secure banking systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0718b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated account data (in production, this would be a secure API call)\n",
    "MOCK_ACCOUNTS = {\n",
    "    \"CHK-12345\": {\"type\": \"Checking\", \"balance\": 5432.10, \"currency\": \"USD\"},\n",
    "    \"SAV-67890\": {\"type\": \"Savings\", \"balance\": 15750.00, \"currency\": \"USD\"},\n",
    "    \"CHK-11111\": {\"type\": \"Checking\", \"balance\": 892.45, \"currency\": \"USD\"},\n",
    "}\n",
    "\n",
    "MOCK_TRANSACTIONS = {\n",
    "    \"CHK-12345\": [\n",
    "        {\"date\": \"2026-01-15\", \"description\": \"Direct Deposit - Payroll\", \"amount\": 3500.00},\n",
    "        {\"date\": \"2026-01-14\", \"description\": \"Electric Bill Payment\", \"amount\": -145.50},\n",
    "        {\"date\": \"2026-01-12\", \"description\": \"Grocery Store\", \"amount\": -87.23},\n",
    "        {\"date\": \"2026-01-10\", \"description\": \"ATM Withdrawal\", \"amount\": -200.00},\n",
    "    ],\n",
    "    \"SAV-67890\": [\n",
    "        {\"date\": \"2026-01-01\", \"description\": \"Interest Credit\", \"amount\": 12.50},\n",
    "        {\"date\": \"2025-12-15\", \"description\": \"Transfer from Checking\", \"amount\": 500.00},\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "def get_account_balance(account_number: str) -> dict:\n",
    "    \"\"\"Simulate looking up account balance from banking system.\"\"\"\n",
    "    if account_number in MOCK_ACCOUNTS:\n",
    "        account = MOCK_ACCOUNTS[account_number]\n",
    "        return {\n",
    "            \"account_number\": account_number,\n",
    "            \"account_type\": account[\"type\"],\n",
    "            \"balance\": account[\"balance\"],\n",
    "            \"currency\": account[\"currency\"],\n",
    "            \"status\": \"active\"\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"error\": \"Account not found\",\n",
    "            \"account_number\": account_number\n",
    "        }\n",
    "\n",
    "\n",
    "def get_recent_transactions(account_number: str, num_transactions: int = 5) -> dict:\n",
    "    \"\"\"Simulate looking up recent transactions from banking system.\"\"\"\n",
    "    num_transactions = min(num_transactions, 10)  # Cap at 10\n",
    "    \n",
    "    if account_number in MOCK_TRANSACTIONS:\n",
    "        transactions = MOCK_TRANSACTIONS[account_number][:num_transactions]\n",
    "        return {\n",
    "            \"account_number\": account_number,\n",
    "            \"transactions\": transactions,\n",
    "            \"count\": len(transactions)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"error\": \"Account not found or no transactions available\",\n",
    "            \"account_number\": account_number\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Tool functions implemented\")\n",
    "print(f\"   Mock accounts available: {list(MOCK_ACCOUNTS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5704ae9",
   "metadata": {},
   "source": [
    "## 5. Create Banking Assistant Agent with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573fdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Banking Assistant Agent with function tools\n",
    "agent = project_client.agents.create_version(\n",
    "    agent_name=\"banking-assistant-with-tools\",\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=model_deployment,\n",
    "        instructions=\"\"\"\n",
    "        You are a helpful Banking Assistant that can look up account information.\n",
    "        \n",
    "        You have access to the following tools:\n",
    "        - get_account_balance: Look up the current balance for an account\n",
    "        - get_recent_transactions: Get recent transactions for an account\n",
    "        \n",
    "        Guidelines:\n",
    "        1. Always use the appropriate tool when a customer asks about their account\n",
    "        2. Present balance information clearly with proper currency formatting\n",
    "        3. Summarize transactions in a helpful way\n",
    "        4. If an account is not found, politely inform the customer\n",
    "        5. Never reveal sensitive implementation details about the banking system\n",
    "        6. Always maintain a professional and helpful tone\n",
    "        \n",
    "        Security Notice: Only provide information for accounts the customer specifies.\n",
    "        \"\"\",\n",
    "        tools=tools,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"üéâ Agent created (name: {agent.name}, version: {agent.version})\")\n",
    "print(f\"   Tools attached: {len(tools)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3bb5db",
   "metadata": {},
   "source": [
    "## 6. Test the Agent with Tool Calls\n",
    "\n",
    "Let's test the agent and handle the function calls. This interaction will be used for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c43830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query that should trigger tool usage\n",
    "test_query = \"What is the balance in my checking account CHK-12345? Also show me my recent transactions.\"\n",
    "\n",
    "print(f\"üë§ Customer: {test_query}\")\n",
    "print(\"\\nüîÑ Calling agent...\")\n",
    "\n",
    "# Initial response from agent (may include function calls)\n",
    "response = openai_client.responses.create(\n",
    "    input=test_query,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    ")\n",
    "\n",
    "print(f\"\\nüì• Initial Response:\")\n",
    "print(f\"   Response ID: {response.id}\")\n",
    "print(f\"   Output text: {response.output_text}\")\n",
    "print(f\"   Output items: {len(response.output)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65114cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process function calls from the agent\n",
    "input_list: ResponseInputParam = []\n",
    "\n",
    "print(\"\\nüîß Processing function calls...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for item in response.output:\n",
    "    if item.type == \"function_call\":\n",
    "        print(f\"\\nüìû Function call: {item.name}\")\n",
    "        print(f\"   Arguments: {item.arguments}\")\n",
    "        \n",
    "        # Parse arguments and execute the appropriate function\n",
    "        args = json.loads(item.arguments)\n",
    "        \n",
    "        if item.name == \"get_account_balance\":\n",
    "            result = get_account_balance(**args)\n",
    "        elif item.name == \"get_recent_transactions\":\n",
    "            result = get_recent_transactions(**args)\n",
    "        else:\n",
    "            result = {\"error\": f\"Unknown function: {item.name}\"}\n",
    "        \n",
    "        print(f\"   Result: {result}\")\n",
    "        \n",
    "        # Add function call output to input list\n",
    "        input_list.append(\n",
    "            FunctionCallOutput(\n",
    "                type=\"function_call_output\",\n",
    "                call_id=item.call_id,\n",
    "                output=json.dumps(result),\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"\\n‚úÖ Processed {len(input_list)} function calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dafbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there were function calls, send results back to get final response\n",
    "if input_list:\n",
    "    print(\"\\nüîÑ Sending function results back to agent...\")\n",
    "    \n",
    "    final_response = openai_client.responses.create(\n",
    "        input=input_list,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "        previous_response_id=response.id,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nü§ñ Agent Final Response:\")\n",
    "    print(f\"   Response ID: {final_response.id}\")\n",
    "    print(f\"\\n   {final_response.output_text}\")\n",
    "    \n",
    "    # Use final response for evaluation\n",
    "    response_for_eval = final_response\n",
    "else:\n",
    "    print(\"\\nü§ñ Agent Response (no function calls):\")\n",
    "    print(f\"   {response.output_text}\")\n",
    "    response_for_eval = response\n",
    "\n",
    "print(f\"\\nüìù Response ID for evaluation: {response_for_eval.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe380e",
   "metadata": {},
   "source": [
    "## 7. Configure Evaluation for Response with Tools\n",
    "\n",
    "We'll evaluate the agent's response using the `azure_ai_responses` data source, which allows us to evaluate a specific response by ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bb855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.eval_create_params import DataSourceConfigCustom\n",
    "\n",
    "# Define data source config for response evaluation\n",
    "data_source_config = DataSourceConfigCustom(\n",
    "    type=\"custom\",\n",
    "    item_schema={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"resp_id\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"resp_id\"]\n",
    "    },\n",
    "    include_sample_schema=True,\n",
    ")\n",
    "\n",
    "# Testing criteria for evaluating tool-enabled responses\n",
    "testing_criteria = [\n",
    "    {\n",
    "        \"type\": \"azure_ai_evaluator\",\n",
    "        \"name\": \"violence_detection\",\n",
    "        \"evaluator_name\": \"builtin.violence\",\n",
    "        \"data_mapping\": {\n",
    "            \"query\": \"{{item.resp_id}}\",  # Using resp_id as placeholder\n",
    "            \"response\": \"{{sample.output_text}}\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"azure_ai_evaluator\",\n",
    "        \"name\": \"fluency\",\n",
    "        \"evaluator_name\": \"builtin.fluency\",\n",
    "        \"initialization_parameters\": {\n",
    "            \"deployment_name\": model_deployment\n",
    "        },\n",
    "        \"data_mapping\": {\n",
    "            \"query\": \"{{item.resp_id}}\",\n",
    "            \"response\": \"{{sample.output_text}}\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"azure_ai_evaluator\",\n",
    "        \"name\": \"task_adherence\",\n",
    "        \"evaluator_name\": \"builtin.task_adherence\",\n",
    "        \"initialization_parameters\": {\n",
    "            \"deployment_name\": model_deployment\n",
    "        },\n",
    "        \"data_mapping\": {\n",
    "            \"query\": \"{{item.resp_id}}\",\n",
    "            \"response\": \"{{sample.output_items}}\"  # Includes tool call info\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Evaluation criteria configured for tool-enabled responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b95f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation object\n",
    "eval_object = openai_client.evals.create(\n",
    "    name=\"Agent Response Evaluation with Tools\",\n",
    "    data_source_config=data_source_config,\n",
    "    testing_criteria=testing_criteria,  # type: ignore\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Evaluation created (id: {eval_object.id}, name: {eval_object.name})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d7822",
   "metadata": {},
   "source": [
    "## 8. Run Evaluation on the Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17844a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data source to evaluate the specific response\n",
    "data_source = {\n",
    "    \"type\": \"azure_ai_responses\",\n",
    "    \"item_generation_params\": {\n",
    "        \"type\": \"response_retrieval\",\n",
    "        \"data_mapping\": {\n",
    "            \"response_id\": \"{{item.resp_id}}\"\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"type\": \"file_content\",\n",
    "            \"content\": [\n",
    "                {\"item\": {\"resp_id\": response_for_eval.id}}\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create and run the evaluation\n",
    "response_eval_run: Union[RunCreateResponse, RunRetrieveResponse] = openai_client.evals.runs.create(\n",
    "    eval_id=eval_object.id,\n",
    "    name=f\"Evaluation Run for Agent {agent.name} with Tools\",\n",
    "    data_source=data_source  # type: ignore\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Evaluation run created (id: {response_eval_run.id})\")\n",
    "print(f\"‚è≥ Status: {response_eval_run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for evaluation completion\n",
    "print(\"‚è≥ Waiting for evaluation to complete...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "while response_eval_run.status not in [\"completed\", \"failed\"]:\n",
    "    response_eval_run = openai_client.evals.runs.retrieve(\n",
    "        run_id=response_eval_run.id,\n",
    "        eval_id=eval_object.id\n",
    "    )\n",
    "    print(f\"   Status: {response_eval_run.status}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "if response_eval_run.status == \"completed\":\n",
    "    print(\"\\n‚úÖ Evaluation run completed successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Evaluation run failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c29f7b2",
   "metadata": {},
   "source": [
    "## 9. Analyze Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20014fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response_eval_run.status == \"completed\":\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä EVALUATION RESULTS - Agent with Function Tools\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Display result counts\n",
    "    print(f\"\\nüìà Result Counts: {response_eval_run.result_counts}\")\n",
    "    \n",
    "    # Get output items\n",
    "    output_items = list(\n",
    "        openai_client.evals.runs.output_items.list(\n",
    "            run_id=response_eval_run.id,\n",
    "            eval_id=eval_object.id\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìù OUTPUT ITEMS (Total: {len(output_items)})\")\n",
    "    \n",
    "    # Display report URL\n",
    "    if response_eval_run.report_url:\n",
    "        print(f\"\\nüîó Eval Run Report URL: {response_eval_run.report_url}\")\n",
    "    \n",
    "    # Pretty print detailed results\n",
    "    print(\"\\nüìã Detailed Results:\")\n",
    "    print(\"-\" * 60)\n",
    "    pprint(output_items)\n",
    "    print(\"-\" * 60)\n",
    "else:\n",
    "    print(\"\\n‚ùå Cannot display results - evaluation did not complete successfully.\")\n",
    "    if response_eval_run.report_url:\n",
    "        print(f\"üîó Check report URL for details: {response_eval_run.report_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d50b3",
   "metadata": {},
   "source": [
    "## 10. Summary - Tool Evaluation Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä EVALUATION SUMMARY - Agent with Function Tools\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüîß Tools Evaluated:\")\n",
    "print(\"   ‚Ä¢ get_account_balance - Account balance lookup\")\n",
    "print(\"   ‚Ä¢ get_recent_transactions - Transaction history\")\n",
    "\n",
    "print(\"\\nüéØ Evaluation Metrics:\")\n",
    "print(\"   ‚Ä¢ Violence Detection - Safety check on responses\")\n",
    "print(\"   ‚Ä¢ Fluency - Quality of natural language output\")\n",
    "print(\"   ‚Ä¢ Task Adherence - Correct tool usage and response\")\n",
    "\n",
    "print(\"\\nüíº FSI Compliance Insights:\")\n",
    "print(\"   ‚Ä¢ Tool calls were logged and can be audited\")\n",
    "print(\"   ‚Ä¢ Response includes proper account information\")\n",
    "print(\"   ‚Ä¢ No sensitive data exposed beyond what was requested\")\n",
    "\n",
    "print(\"\\nüìù Key Differences from Basic Evaluation:\")\n",
    "print(\"   ‚Ä¢ Uses 'azure_ai_responses' data source type\")\n",
    "print(\"   ‚Ä¢ Evaluates specific response by ID\")\n",
    "print(\"   ‚Ä¢ Captures tool call information in output_items\")\n",
    "\n",
    "if response_eval_run.report_url:\n",
    "    print(f\"\\nüîó View detailed report: {response_eval_run.report_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c86f3",
   "metadata": {},
   "source": [
    "## 11. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54818441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean up resources\n",
    "# try:\n",
    "#     openai_client.evals.delete(eval_id=eval_object.id)\n",
    "#     print(\"üóëÔ∏è Evaluation deleted\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è Could not delete evaluation: {e}\")\n",
    "\n",
    "# try:\n",
    "#     project_client.agents.delete(agent_name=agent.name)\n",
    "#     print(\"üóëÔ∏è Agent deleted\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è Could not delete agent: {e}\")\n",
    "\n",
    "# print(\"\\n‚úÖ Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1feaf",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "‚úÖ **Define function tools** for banking operations (balance lookup, transactions)  \n",
    "‚úÖ **Create an agent with tools** integrated  \n",
    "‚úÖ **Handle function calls** and provide results back to the agent  \n",
    "‚úÖ **Evaluate tool-enabled responses** using `azure_ai_responses` data source  \n",
    "‚úÖ **Analyze results** including tool usage information  \n",
    "\n",
    "### üîß Key APIs Used\n",
    "\n",
    "| API | Purpose |\n",
    "|-----|--------|\n",
    "| `FunctionTool()` | Define a callable tool for the agent |\n",
    "| `openai_client.responses.create()` | Get agent response with tool calls |\n",
    "| `FunctionCallOutput()` | Provide function results back to agent |\n",
    "| `azure_ai_responses` data source | Evaluate specific response by ID |\n",
    "\n",
    "### üìä Evaluation Data Sources\n",
    "\n",
    "| Data Source Type | Use Case |\n",
    "|------------------|----------|\n",
    "| `azure_ai_target_completions` | Evaluate agent with test queries |\n",
    "| `azure_ai_responses` | Evaluate specific response by ID |\n",
    "\n",
    "### üìö Next Steps\n",
    "\n",
    "1. **Add more tools** for comprehensive banking functionality\n",
    "2. **Test edge cases** like invalid accounts or errors\n",
    "3. **Add custom evaluators** for domain-specific criteria\n",
    "4. **Integrate into CI/CD** for continuous agent validation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
